{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56628b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries and add script path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\marku\\Documents\\SteelProdData_Project\\src\\scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalized training and testing data\n",
    "train_data_orig = pd.read_csv('C:\\\\Users\\\\marku\\\\Documents\\\\SteelProdData_Project\\\\data\\\\raw\\\\normalized_train_data.csv')\n",
    "test_data_orig = pd.read_csv('C:\\\\Users\\\\marku\\\\Documents\\\\SteelProdData_Project\\\\data\\\\raw\\\\normalized_test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat training and testing data for Data Exploration\n",
    "conc_data=pd.concat([train_data_orig, test_data_orig], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "\n",
    "# Define a set of values that should be treated as empty/missing\n",
    "EMPTY_TOKENS = {\"\", \" \", \"NA\", \"N/A\", \"null\", \"None\", \"nan\", \"-\"}\n",
    "\n",
    "# Create a copy of the dataframe to avoid modifying the original\n",
    "conc_data_check = conc_data.copy()\n",
    "\n",
    "# Convert empty strings and placeholder values to NaN in object columns\n",
    "obj_cols = conc_data_check.select_dtypes(include=[\"object\"]).columns\n",
    "for c in obj_cols:\n",
    "    conc_data_check[c] = (\n",
    "        conc_data_check[c]\n",
    "        .astype(str)        # Convert all values to strings\n",
    "        .str.strip()        # Remove leading/trailing whitespace\n",
    "        .replace(EMPTY_TOKENS, np.nan)  # Replace empty tokens with NaN\n",
    "    )\n",
    "\n",
    "# Create a summary dataframe with statistics about each column\n",
    "summary = pd.DataFrame({\n",
    "    \"dtype\": conc_data_check.dtypes.astype(str),      # Data type of each column\n",
    "    \"rows_total\": len(conc_data_check),               # Total number of rows\n",
    "    \"non_null\": conc_data_check.notna().sum(),        # Count of non-null values\n",
    "    \"nulls\": conc_data_check.isna().sum(),            # Count of null values\n",
    "    \"null_frac\": (conc_data_check.isna().mean()),     # n_NaN/n_all_Entries\n",
    "    \"n_unique\": conc_data_check.nunique(dropna=True), # Count of unique non-null values\n",
    "})\n",
    "# Sort the summary by null fraction\n",
    "summary = summary.sort_values(\"null_frac\", ascending=False)\n",
    "\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e417c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing values with mean of the columns -Not necessary\n",
    "numerical_cols = conc_data.select_dtypes(include=np.number).columns.tolist() \n",
    "conc_data[numerical_cols] = conc_data[numerical_cols].apply(lambda x: x.fillna(x.mean()), axis=0) # Fill NaN with column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4791dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicates\n",
    "\n",
    "# Count duplicate rows based on all input and output columns\n",
    "n_dup = conc_data_check.duplicated().sum()\n",
    "print(f\"Duplikate über input1..input21 + output: {n_dup}\")\n",
    "\n",
    "# Display duplicate rows\n",
    "dup_rows = conc_data_check[conc_data_check.duplicated(keep=False)].copy()\n",
    "\n",
    "display(dup_rows.head(5))  # Display first 5 duplicate rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_data_orig[\"output\"])\n",
    "plt.hist(test_data_orig[\"output\"])\n",
    "plt.xlabel('Output')\n",
    "plt.ylabel('n') \n",
    "plt.title('Distribution of Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb39fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "g=sns.pairplot(conc_data.sample(n=300, random_state=42)) #Plot pairwise relationships with sample of 300 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "\n",
    "num_cols = conc_data.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "num_cols.remove(\"output\")                             #Remove column output from correlation analysis\n",
    "\n",
    "# Plot correlation heatmap\n",
    "corr_cols = num_cols[:]             #List of numerical columns for correlation\n",
    "corr = conc_data[corr_cols].corr()  \n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr.values, aspect=\"auto\")\n",
    "plt.title(\"Korrelation\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xticks(range(len(corr_cols)), corr_cols, rotation=90, fontsize=8) #Rotate x-axis labels for better readability\n",
    "plt.yticks(range(len(corr_cols)), corr_cols, fontsize=8) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=conc_data.drop(\"output\" , axis=1 ).values\n",
    "y=conc_data[\"output\"].values\n",
    "\n",
    "# Standardize the inputs \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reduce the 21 features down to 2\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "#For plotting cumulative variance\n",
    "pca_2=PCA()  \n",
    "pca_2.fit(X_scaled)\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.5) #Y-values as color\n",
    "plt.colorbar(label='Output Value')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Analysis: Features reduced to 2D')\n",
    "plt.show()\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "cumulative_variance=np.cumsum(pca_2.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(range(1,22),cumulative_variance, marker='o', linestyle='--')\n",
    "\n",
    "#Add horizontal lines for 90% and 95% variance\n",
    "plt.axhline(y=0.90, color='r', linestyle='-', label='90% Variance')\n",
    "plt.axhline(y=0.95, color='g', linestyle='-', label='95% Variance')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Variance: How much info do we keep?')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test/Train_Split\n",
    "X=conc_data.drop(\"output\" , axis=1 ).values\n",
    "y=conc_data[\"output\"].values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a827bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish Baseline Model with Linear Regression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#s=StandardScaler()       #Data is standardized using Min-Max Scaling\n",
    "#s.fit(X_train) \n",
    "\n",
    "#X_train_trans= s.transform(X_train) \n",
    "#X_test_trans=s.transform(X_test)\n",
    "\n",
    "model_lr=LinearRegression()\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "print(model_lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestRegressor default parameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_rfreg=RandomForestRegressor()\n",
    "\n",
    "model_rfreg.fit(X_train, y_train)\n",
    "\n",
    "print(model_rfreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfc3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Gaussian Process (RBF and COnstant Kernel)\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "# Define the kernel (covariance function)\n",
    "# Here we use a constant kernel multiplied by an RBF kernel\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "model_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1)\n",
    "model_gp.fit(X_train, y_train)\n",
    "\n",
    "from plot_helper import evaluate_model, plot_data\n",
    "evaluate_model(model_gp, X_test, y_test)\n",
    "plot_data(X_test, y_test, model_gp.predict(X_test), title=\"Model Predictions vs Ground Truth on Test Data\")\n",
    "\n",
    "\n",
    "#Terminated due to runtime issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the specific gpytorch site-packages path to sys.path and try import\n",
    "import sys\n",
    "sys.path.append(r'c:\\users\\marku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages')\n",
    "\n",
    "#sys.path.append(r'C:\\Users\\marku\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\Scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0906792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mixed Gaussian Process (COnstant Kernel, Matern, DotProduct, Noise)\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, DotProduct, WhiteKernel, ConstantKernel\n",
    "\n",
    "# Define the kernel (covariance function)\n",
    "\n",
    "kernel = (ConstantKernel(1.0, (1e-3, 1e3)) * Matern(length_scale=[1.0]*21, nu=1.5) + \n",
    "    DotProduct(sigma_0=1.0) + \n",
    "    WhiteKernel(noise_level=0.1)\n",
    ")\n",
    "model_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1)\n",
    "model_gp.fit(X_train, y_train)\n",
    "\n",
    "from plot_helper import evaluate_model, plot_data\n",
    "evaluate_model(model_gp, X_test, y_test)\n",
    "plot_data(X_test, y_test, model_gp.predict(X_test), title=\"Model Predictions vs Ground Truth on Test Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Check if CUDA is reachable\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 2. Check the version PyTorch is using\n",
    "print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# 3. Check the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fecc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-accelerated Gaussian Process using GPyTorch (uses CUDA if available)\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "s=StandardScaler()       \n",
    "s.fit(X_train) \n",
    "\n",
    "X_train_trans= s.transform(X_train) \n",
    "X_test_trans=s.transform(X_test)\n",
    "\n",
    "# Select device (GPU if available, else CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Convert numpy data to torch tensors on the selected device\n",
    "X_train_t = torch.from_numpy(X_train_trans.astype(np.float32)).to(device)\n",
    "y_train_t = torch.from_numpy(y_train.astype(np.float32)).to(device)\n",
    "X_test_t = torch.from_numpy(X_test_trans.astype(np.float32)).to(device)\n",
    "y_test_t = torch.from_numpy(y_test.astype(np.float32)).to(device)\n",
    "\n",
    "# Define the GP model\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=21)\n",
    "        ) + gpytorch.kernels.LinearKernel()\n",
    "        #self.covar_module[0].outputscale = 1.2 #Manually set the initial weight, since preds are offset in plot_data\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "# Initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "model_gt = ExactGPModel(X_train_t, y_train_t, likelihood).to(device)\n",
    "\n",
    "# Train the model \n",
    "model_gt.train()\n",
    "likelihood.train()\n",
    "\n",
    "#Use the Adam optimizer from torch\n",
    "optimizer = torch.optim.Adam(model_gt.parameters(), lr=0.1) \n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model_gt)\n",
    "\n",
    "# Training loop\n",
    "training_iter = 100\n",
    "for i in range(training_iter):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_gt(X_train_t)\n",
    "    loss = -mll(output, y_train_t)\n",
    "    loss.backward()\n",
    "    print(f'Iter {i+1}/{training_iter} - Loss: {loss.item():.4f}')\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluation \n",
    "model_gt.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = likelihood(model_gt(X_test_t)) #equal to scikit learn .predict()\n",
    "    mean = preds.mean.cpu().numpy()        #convert to numpy on CPU\n",
    "    \n",
    "# Metrics and plotting\n",
    "r2 = r2_score(y_test, mean)\n",
    "mae = mean_absolute_error(y_test, mean)\n",
    "mse = mean_squared_error(y_test, mean)\n",
    "print(f'GPyTorch GPU GP — R2: {r2:.4f}, MAE: {mae:.4f}, MSE: {mse:.4f}')\n",
    "from plot_helper import plot_data\n",
    "plot_data(X_test, y_test, mean, title='GPyTorch GPU Gaussian Process Predictions vs Ground Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense  \n",
    "\n",
    "#Define NN model\n",
    "model_dnnstd = Sequential() \n",
    "model_dnnstd.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],) )) #21 Inputs as Dense layer\n",
    "model_dnnstd.add(Dense(1,activation='linear')) # linear Output layer\n",
    "\n",
    "model_dnnstd.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "#Train the NN model and save training history\n",
    "history_dnnstd=model_dnnstd.fit(\n",
    "          X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e36c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "\n",
    "#Define DNN model and use \"diamond\" shape 512-256-128-64-64-1\n",
    "model_dnnopt = models.Sequential()\n",
    "model_dnnopt.add(Dense(512, activation='relu', input_shape=(21,),kernel_regularizer=regularizers.l2(1e-4))) #21 Inputs and Dense layer already imported above\n",
    "model_dnnopt.add(layers.BatchNormalization()) #Batch Normalization layer\n",
    "\n",
    "\n",
    "model_dnnopt.add(Dense(256, activation='relu')) #256 Neurons\n",
    "model_dnnopt.add(layers.Dropout(0.3))         #Dropout layer to reduce overfitting\n",
    "model_dnnopt.add(Dense(128, activation='relu')) # 128 Neurons\n",
    "model_dnnopt.add(layers.BatchNormalization()) \n",
    "\n",
    "model_dnnopt.add(Dense(64, activation='relu'))\n",
    "model_dnnopt.add(Dense(64, activation='relu'))\n",
    "model_dnnopt.add(Dense(1,activation='linear')) #Linear output layer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "\n",
    "model_dnnopt.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae','mse'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403320cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define learning rate scheduler and early stopping\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2,    # Cut LR by 80% when progress stalls\n",
    "    patience=5,    # Wait 5 epochs before reducing LR\n",
    "    min_lr=1e-7,   # Set a minimum learning rate\n",
    "    verbose=1      # Print Message when LR is reduced\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss for early stopping\n",
    "    patience=12,         # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True # Restore model weights from the epoch with the best value\n",
    ")\n",
    "\n",
    "\n",
    "history_dnnopt = model_dnnopt.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=200,          # Increased epochs to allow LR scheduler to work\n",
    "    batch_size=32,       \n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval linear regression\n",
    "\n",
    "from plot_helper import evaluate_model, plot_data\n",
    "evaluate_model(model_lr, X_test, y_test)\n",
    "plot_data(X_test, y_test, model_lr.predict(X_test), title=\"Model Predictions vs Ground Truth on Test Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval RFRegressor\n",
    "\n",
    "from plot_helper import evaluate_model, plot_data\n",
    "evaluate_model(model_rfreg, X_test, y_test)\n",
    "plot_data(X_test, y_test, model_rfreg.predict(X_test), title=\"Model Predictions vs Ground Truth on Test Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d27731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval DNN standard\n",
    "\n",
    "from plot_helper import evaluate_model, plot_data\n",
    "evaluate_model(model_dnnstd, X_test, y_test)\n",
    "plot_data(X_test, y_test, model_dnnstd.predict(X_test), title=\"Model Predictions vs Ground Truth on Test Data\")\n",
    "plot_loss(history_dnnstd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32422823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval DNN optimized\n",
    "\n",
    "from plot_helper import evaluate_model, plot_data\n",
    "evaluate_model(model_dnnopt, X_test, y_test)\n",
    "plot_data(X_test, y_test, model_dnnopt.predict(X_test), title=\"Model Predictions vs Ground Truth on Test Data\")\n",
    "plot_loss(history_dnnopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "names = ['Linear Regression', 'Random Forest Regressor', 'DNN Optimized', 'DNN Standard', 'GPyTorch GPU GP']\n",
    "models_map = {\n",
    "    'Linear Regression': globals().get('model_lr'),\n",
    "    'Random Forest Regressor': globals().get('model_rfreg'),\n",
    "    'DNN Optimized': globals().get('model_dnnopt'),\n",
    "    'DNN Standard': globals().get('model_dnnstd'),\n",
    "    'GPyTorch GPU GP': globals().get('model_gt'),\n",
    "}\n",
    "r2_list = []\n",
    "rmse_list = []\n",
    "for n in names:\n",
    "    if n == 'GPyTorch GPU GP':  #Pytorch model needs special handling\n",
    "        with torch.no_grad(): \n",
    "            preds = likelihood(model_gt(X_test_t)) #equal to scikit learn .predict()\n",
    "            preds = preds.mean.cpu().numpy() #convert to numpy on CPU\n",
    "    else:\n",
    "        mdl = models_map.get(n)\n",
    "        preds = mdl.predict(X_test)\n",
    "        preds = np.asarray(preds).reshape(-1)\n",
    "\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2_list.append(r2)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "r2s = np.array(r2_list, dtype=float)\n",
    "rmses = np.array(rmse_list, dtype=float)\n",
    "\n",
    "\n",
    "colors = ['#4C72B0', '#DD8452', '#55A868', '#C44E52', '#8172B2']\n",
    "\n",
    "# Create wide figure with two subplots side-by-side\n",
    "fig = plt.figure(figsize=(14, 4.5))\n",
    "fig.suptitle('Model Performance: R² and RMSE', fontsize=22, fontweight='bold')\n",
    "\n",
    "# Left subplot: R²\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "x = np.arange(len(names))\n",
    "bars1 = ax1.bar(x, r2s, color=colors, edgecolor='black', linewidth=0.7)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(names, rotation=25, ha='right', fontsize=10) #Rotate x-axis labels for better readability\n",
    "ax1.set_ylabel('R²', fontsize=12)\n",
    "ax1.set_ylim(0.0, 1.0)\n",
    "ax1.set_title('R² Score (higher is better)', fontsize=14)\n",
    "ax1.yaxis.grid(True, linestyle='--', linewidth=0.6, alpha=0.6) \n",
    "plt.axhline(y=0.50, color='r', linestyle='-', label='50% R2') #Add horizontal line at R² = 0.50\n",
    "\n",
    "# Add numeric labels above each R² bar\n",
    "for rect, val in zip(bars1, r2s):\n",
    "    height = rect.get_height()\n",
    "    ax1.text(rect.get_x() + rect.get_width() / 2, height + 0.02, f'{val:.4f}', ha='center', va='bottom', fontsize=10) #.4f for 4 decimal places\n",
    "\n",
    "# Right subplot: RMSE\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "bars2 = ax2.bar(x, rmses, color=colors, edgecolor='black', linewidth=0.7)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(names, rotation=25, ha='right', fontsize=10) #Rotate x-axis labels for better readability\n",
    "ax2.set_ylabel('RMSE', fontsize=12)\n",
    "ax2.set_title('RMSE (lower is better)', fontsize=14)\n",
    "ax2.yaxis.grid(True, linestyle='--', linewidth=0.6, alpha=0.6)\n",
    "\n",
    "# Add numeric labels above each RMSE bar\n",
    "for rect, val in zip(bars2, rmses):\n",
    "    height = rect.get_height()\n",
    "    ax2.text(rect.get_x() + rect.get_width() / 2, height + 0.0022, f'{val:.4f}', ha='center', va='bottom', fontsize=10) #.4f for 4 decimal places\n",
    "\n",
    "# Tight layout and show\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
